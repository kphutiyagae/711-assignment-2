{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-26T21:32:58.868128Z",
     "start_time": "2025-09-26T21:32:58.866367Z"
    }
   },
   "source": [
    "import pandas as pd #Import pandas for operations\n",
    "from sympy.printing.pytorch import torch"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:32:59.280850Z",
     "start_time": "2025-09-26T21:32:58.890055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframe = pd.read_csv('data/sdss_100k_galaxy_form_burst.csv', low_memory=False, header=1)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {dataframe.shape}\")\n",
    "print(f\"Columns: {list(dataframe.columns)}\")\n",
    "print(f\"Datatypes: {dataframe.dtypes}\")"
   ],
   "id": "e8d22af5cfcdf8af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Dataset shape: (100000, 43)\n",
      "Columns: ['objid', 'specobjid', 'ra', 'dec', 'u', 'g', 'r', 'i', 'z', 'modelFlux_u', 'modelFlux_g', 'modelFlux_r', 'modelFlux_i', 'modelFlux_z', 'petroRad_u', 'petroRad_g', 'petroRad_i', 'petroRad_r', 'petroRad_z', 'petroFlux_u', 'petroFlux_g', 'petroFlux_i', 'petroFlux_r', 'petroFlux_z', 'petroR50_u', 'petroR50_g', 'petroR50_i', 'petroR50_r', 'petroR50_z', 'psfMag_u', 'psfMag_r', 'psfMag_g', 'psfMag_i', 'psfMag_z', 'expAB_u', 'expAB_g', 'expAB_r', 'expAB_i', 'expAB_z', 'class', 'subclass', 'redshift', 'redshift_err']\n",
      "Datatypes: objid             int64\n",
      "specobjid        uint64\n",
      "ra              float64\n",
      "dec             float64\n",
      "u               float64\n",
      "g               float64\n",
      "r               float64\n",
      "i               float64\n",
      "z               float64\n",
      "modelFlux_u     float64\n",
      "modelFlux_g     float64\n",
      "modelFlux_r     float64\n",
      "modelFlux_i     float64\n",
      "modelFlux_z     float64\n",
      "petroRad_u      float64\n",
      "petroRad_g      float64\n",
      "petroRad_i      float64\n",
      "petroRad_r      float64\n",
      "petroRad_z      float64\n",
      "petroFlux_u     float64\n",
      "petroFlux_g     float64\n",
      "petroFlux_i     float64\n",
      "petroFlux_r     float64\n",
      "petroFlux_z     float64\n",
      "petroR50_u      float64\n",
      "petroR50_g      float64\n",
      "petroR50_i      float64\n",
      "petroR50_r      float64\n",
      "petroR50_z      float64\n",
      "psfMag_u        float64\n",
      "psfMag_r        float64\n",
      "psfMag_g        float64\n",
      "psfMag_i        float64\n",
      "psfMag_z        float64\n",
      "expAB_u         float64\n",
      "expAB_g         float64\n",
      "expAB_r         float64\n",
      "expAB_i         float64\n",
      "expAB_z         float64\n",
      "class            object\n",
      "subclass         object\n",
      "redshift        float64\n",
      "redshift_err    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:32:59.285750Z",
     "start_time": "2025-09-26T21:32:59.284107Z"
    }
   },
   "cell_type": "code",
   "source": "# dataframe['subclass'].unique()\n",
   "id": "3fdbe24f7d64288f",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:32:59.332906Z",
     "start_time": "2025-09-26T21:32:59.290393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#1 Data pre-processing\n",
    "\n",
    "#1.1.1 remove unnecessary columns\n",
    "modified_dataframe = dataframe.drop(['objid', 'specobjid', 'class'], axis=1)\n",
    "\n",
    "# #1.1.2 Encode subclass category accordingly\n",
    "# modified_dataframe['subclass'] = modified_dataframe['subclass'].map({'STARBURST': 1, 'STARFORMING': 0})\n",
    "\n",
    "#1.2.1 Split dataset into Test and Training data. (80% Training - 20% Test)\n",
    "main_training_data = modified_dataframe.sample(frac=0.8)\n",
    "testing_data = modified_dataframe.drop(main_training_data.index)\n",
    "\n",
    "#1.2.2 Split Test data into Test and Validation Set. (70% Training - 30% Validation)\n",
    "training_set = main_training_data.sample(frac=0.7)\n",
    "validation_set = main_training_data.drop(training_set.index)\n"
   ],
   "id": "cf39c68afc7d1fe0",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:32:59.339847Z",
     "start_time": "2025-09-26T21:32:59.336938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Visualize data.\n",
    "#1. Training Set Info\n",
    "print(f\"Training Dataset shape: {training_set.shape}\")\n",
    "print(f\"Training Dataset Columns: {list(training_set.columns)}\")\n",
    "\n",
    "#2. Testing Set Info\n",
    "print(f\"Testing Dataset shape: {testing_data.shape}\")\n",
    "print(f\"Testing Dataset Columns: {list(testing_data.columns)}\")\n",
    "\n",
    "#3. Validation Set Info\n",
    "print(f\"Validation Dataset shape: {validation_set.shape}\")\n",
    "print(f\"Validation Dataset Columns: {list(validation_set.columns)}\")\n",
    "\n",
    "assert(len(training_set) + len(testing_data) + len(validation_set) == len(modified_dataframe)) #Confirm that the lengths match.\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "241d8fbdad094eae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset shape: (56000, 40)\n",
      "Training Dataset Columns: ['ra', 'dec', 'u', 'g', 'r', 'i', 'z', 'modelFlux_u', 'modelFlux_g', 'modelFlux_r', 'modelFlux_i', 'modelFlux_z', 'petroRad_u', 'petroRad_g', 'petroRad_i', 'petroRad_r', 'petroRad_z', 'petroFlux_u', 'petroFlux_g', 'petroFlux_i', 'petroFlux_r', 'petroFlux_z', 'petroR50_u', 'petroR50_g', 'petroR50_i', 'petroR50_r', 'petroR50_z', 'psfMag_u', 'psfMag_r', 'psfMag_g', 'psfMag_i', 'psfMag_z', 'expAB_u', 'expAB_g', 'expAB_r', 'expAB_i', 'expAB_z', 'subclass', 'redshift', 'redshift_err']\n",
      "Testing Dataset shape: (20000, 40)\n",
      "Testing Dataset Columns: ['ra', 'dec', 'u', 'g', 'r', 'i', 'z', 'modelFlux_u', 'modelFlux_g', 'modelFlux_r', 'modelFlux_i', 'modelFlux_z', 'petroRad_u', 'petroRad_g', 'petroRad_i', 'petroRad_r', 'petroRad_z', 'petroFlux_u', 'petroFlux_g', 'petroFlux_i', 'petroFlux_r', 'petroFlux_z', 'petroR50_u', 'petroR50_g', 'petroR50_i', 'petroR50_r', 'petroR50_z', 'psfMag_u', 'psfMag_r', 'psfMag_g', 'psfMag_i', 'psfMag_z', 'expAB_u', 'expAB_g', 'expAB_r', 'expAB_i', 'expAB_z', 'subclass', 'redshift', 'redshift_err']\n",
      "Validation Dataset shape: (24000, 40)\n",
      "Validation Dataset Columns: ['ra', 'dec', 'u', 'g', 'r', 'i', 'z', 'modelFlux_u', 'modelFlux_g', 'modelFlux_r', 'modelFlux_i', 'modelFlux_z', 'petroRad_u', 'petroRad_g', 'petroRad_i', 'petroRad_r', 'petroRad_z', 'petroFlux_u', 'petroFlux_g', 'petroFlux_i', 'petroFlux_r', 'petroFlux_z', 'petroR50_u', 'petroR50_g', 'petroR50_i', 'petroR50_r', 'petroR50_z', 'psfMag_u', 'psfMag_r', 'psfMag_g', 'psfMag_i', 'psfMag_z', 'expAB_u', 'expAB_g', 'expAB_r', 'expAB_i', 'expAB_z', 'subclass', 'redshift', 'redshift_err']\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:32:59.348446Z",
     "start_time": "2025-09-26T21:32:59.344386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_distributions_seaborn(df, figsize=(15, 12)):\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "    # Plot numerical distributions\n",
    "    if len(numerical_cols) > 0:\n",
    "        n_rows = (len(numerical_cols) + 2) // 3\n",
    "        fig, axes = plt.subplots(n_rows, 3, figsize=figsize)\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, col in enumerate(numerical_cols):\n",
    "            sns.histplot(data=df, x=col, ax=axes[i], kde=True, bins=30)\n",
    "            axes[i].axvline(df[col].mean(), color='red', linestyle='--', alpha=0.8)\n",
    "            axes[i].axvline(df[col].median(), color='green', linestyle='--', alpha=0.8)\n",
    "            axes[i].set_title(f'Distribution of {col}')\n",
    "\n",
    "        # Hide empty subplots\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            axes[j].set_visible(False)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Plot categorical distributions\n",
    "    if len(categorical_cols) > 0:\n",
    "        n_rows = (len(categorical_cols) + 2) // 3\n",
    "        fig, axes = plt.subplots(n_rows, 3, figsize=figsize)\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, col in enumerate(categorical_cols):\n",
    "            value_counts = df[col].value_counts().head(10)\n",
    "            sns.barplot(x=value_counts.index, y=value_counts.values, ax=axes[i])\n",
    "            axes[i].set_title(f'Distribution of {col}')\n",
    "            axes[i].tick_params(axis='x', rotation=45)\n",
    "            axes[i].set_ylabel('Count')\n",
    "\n",
    "        # Hide empty subplots\n",
    "        for j in range(i + 1, len(axes)):\n",
    "            axes[j].set_visible(False)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# plot_distributions_seaborn(training_set)"
   ],
   "id": "9747cec447fa3143",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:41:36.758419Z",
     "start_time": "2025-09-26T21:41:36.691815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#2. Normalize data.\n",
    "\n",
    "#2. Apply mean-centering & variance scaling to data\n",
    "\n",
    "#2.1. Define function\n",
    "def standardize_with_sklearn(df):\n",
    "    \"\"\"\n",
    "    Use scikit-learn's StandardScaler for robust standardization\n",
    "    \"\"\"\n",
    "    # Separate numerical and categorical columns\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = df['subclass']\n",
    "\n",
    "    # Create a copy and only scale numerical columns\n",
    "    df_normalized = df.copy()\n",
    "\n",
    "    if len(numerical_cols) > 0:\n",
    "        scaler = StandardScaler()\n",
    "        df_normalized[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "    return df_normalized, categorical_cols\n",
    "\n",
    "testing_data.head(5)\n",
    "#2.2. Apply standardization\n",
    "testing_dataset_normalized, testing_dataset_labels = standardize_with_sklearn(testing_data)\n",
    "training_dataset_normalized, training_dataset_labels = standardize_with_sklearn(training_set)\n",
    "validation_dataset_normalized, validation_dataset_labels = standardize_with_sklearn(validation_set)\n",
    "\n",
    "# testing_dataset_normalized.head(5)\n",
    "# testing_dataset_normalized.shape\n",
    "testing_dataset_labels.shape\n",
    "\n",
    "#1.1.2 Encode subclass category accordingly\n",
    "testing_dataset_labels = testing_dataset_labels.map({'STARBURST': 1, 'STARFORMING': 0})\n",
    "training_dataset_labels = testing_dataset_labels.map({'STARBURST': 1, 'STARFORMING': 0})\n",
    "validation_dataset_labels = testing_dataset_labels.map({'STARBURST': 1, 'STARFORMING': 0})\n",
    "\n"
   ],
   "id": "28b46100eb6db7c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9        0\n",
      "11       0\n",
      "14       0\n",
      "18       0\n",
      "19       0\n",
      "        ..\n",
      "99974    1\n",
      "99975    1\n",
      "99977    0\n",
      "99982    0\n",
      "99991    0\n",
      "Name: subclass, Length: 20000, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:22:04.909563Z",
     "start_time": "2025-09-26T21:22:04.905132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "\n",
    "#3. Begin Training Model.\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "#3.1. Setup Model with Params. TODO: Specify weights!!\n",
    "class galaxy_classification_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(galaxy_classification_nn, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=40, out_features=133)\n",
    "        self.fc2 = nn.Linear(in_features=133, out_features=133)\n",
    "        self.fc3 = nn.Linear(in_features=133, out_features=2)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.linear(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)                  # raw scores (logits)\n",
    "            return x\n"
   ],
   "id": "943943929ce0e60c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:23:31.626617Z",
     "start_time": "2025-09-26T21:23:31.624287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "test = training_dataset_normalized[]\n",
    "print(test)\n",
    "# train_tensor_features = torch.tensor(training_dataset_normalized.values, dtype=torch.float32)\n",
    "# train_tensor_labels = torch.tensor(training_dataset_normalized['subclass'], dtype=torch.float32)\n",
    "#\n",
    "# training_dataset = TensorDataset(train_tensor_features, train_tensor_labels)\n",
    "#\n",
    "# training_dataset_loader = DataLoader(training_dataset, batch_size=64, shuffle=True)"
   ],
   "id": "3ea0e49f54ee9a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000,)\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:22:04.965862Z",
     "start_time": "2025-09-26T21:13:18.097631Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 13,
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#3.2. Init. model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "galaxy_classification_model = galaxy_classification_nn().to(device)\n",
    "\n",
    "#3.2. Setup Optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "error_optimizer = optim.SGD(galaxy_classification_model.parameters(), lr=0.01)\n"
   ],
   "id": "14e996b8ea7bd1f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T21:17:43.123623Z",
     "start_time": "2025-09-26T21:17:43.121720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(5):\n",
    "    galaxy_classification_model.train()\n",
    "    for batch_X, batch_y in training_dataset_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "    error_optimizer.zero_grad()\n",
    "\n",
    "    logits = galaxy_classification_model(batch_X)\n",
    "    loss = loss_function(logits, batch_y)\n",
    "    loss.backward()\n",
    "    error_optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} completed\")\n",
    "\n"
   ],
   "id": "5da70087e978e354",
   "outputs": [],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
